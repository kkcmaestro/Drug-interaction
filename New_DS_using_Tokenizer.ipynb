{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9I9m9ALWWEF0",
        "outputId": "26de8e38-823f-4aec-b239-7b514108482f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.11.17)\n"
          ]
        }
      ],
      "source": [
        "pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from transformers import BertTokenizer, BertForPreTraining\n",
        "import torch\n",
        "\n",
        "# Load your drug dataset\n",
        "df = pd.read_csv('new DS.csv')\n",
        "\n",
        "# Display the first few rows of the dataset\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KbgTn03VWMJs",
        "outputId": "7f40114e-c270-4b29-84c0-1eb2268fa564"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Pka   Molecular Weight  Drug Affinity   Solubility              Name  \\\n",
            "0  8.5              300.5           High           50           Aspirin   \n",
            "1  7.0              450.2       Moderate           30         Ibuprofen   \n",
            "2  9.2              600.8            Low           20   Diphenhydramine   \n",
            "3  6.8              700.3           High           40         Metformin   \n",
            "4  5.5              550.6      Very High           25          Warfarin   \n",
            "\n",
            "   Side Effects                          Use  \\\n",
            "0      Headache                  Pain relief   \n",
            "1        Nausea       Inflammation reduction   \n",
            "2    Drowsiness               Allergy relief   \n",
            "3      Diarrhea   Type 2 diabetes management   \n",
            "4      Bleeding              Anticoagulation   \n",
            "\n",
            "                      Mechanism of Action                       Dosage  \\\n",
            "0   Inhibition of prostaglandin synthesis       500 mg every 4-6 hours   \n",
            "1                   COX enzyme inhibition   200-400 mg every 4-6 hours   \n",
            "2             Histamine receptor blockade     25-50 mg every 4-6 hours   \n",
            "3                         AMPK activation            500-2000 mg daily   \n",
            "4                    Vitamin K antagonist                     Variable   \n",
            "\n",
            "     Contraindications  \n",
            "0   Bleeding disorders  \n",
            "1        Peptic ulcers  \n",
            "2             Glaucoma  \n",
            "3   Kidney dysfunction  \n",
            "4      Active bleeding  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "text_data = df[[' Drug Affinity',' Name', ' Side Effects', ' Use', ' Mechanism of Action', ' Contraindications']].astype(str)\n",
        "tokenized_text = tokenizer(text_data.values.flatten().tolist(), return_tensors='pt', padding=True, truncation=True)\n",
        "\n",
        "# Normalize numerical features\n",
        "numerical_data = df[['Pka', ' Molecular Weight', ' Solubility']]\n",
        "numerical_data = (numerical_data - numerical_data.mean()) / numerical_data.std()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cHAGuLjZWQ_Y",
        "outputId": "16c9c352-7ca5-4302-a1fb-e35996f055bb"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = tokenized_text['input_ids']\n",
        "attention_mask = tokenized_text['attention_mask']\n",
        "numerical_input = torch.tensor(numerical_data.values, dtype=torch.float32)\n",
        "\n",
        "# Concatenate tokenized text and numerical input\n",
        "model_input = {'input_ids': input_ids, 'attention_mask': attention_mask, 'numerical_input': numerical_input}"
      ],
      "metadata": {
        "id": "JLASnIyvW0LE"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: Using a custom model that takes both textual and numerical inputs\n",
        "class CustomModel(BertForPreTraining):\n",
        "    def forward(self, input_ids=None, attention_mask=None, numerical_input=None):\n",
        "        outputs = super().forward(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        pooled_output = outputs['pooler_output']\n",
        "        combined_output = torch.cat([pooled_output, numerical_input], dim=1)\n",
        "        # Add your custom layers or predictions here\n",
        "        return combined_output\n",
        "\n",
        "model = CustomModel.from_pretrained('bert-base-uncased')\n",
        "outputs = model(**model_input)"
      ],
      "metadata": {
        "id": "UFqz-HapW8lh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained('pretrained_drug_model')"
      ],
      "metadata": {
        "id": "8ov9YCRyXIGn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}